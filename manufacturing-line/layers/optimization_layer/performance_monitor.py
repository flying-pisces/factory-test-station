"""
Real-Time Performance Monitor - Week 14: Performance Optimization & Scalability

This module provides enterprise-grade real-time performance monitoring capabilities for
the manufacturing system with sub-second metric collection, anomaly detection, and
comprehensive SLA monitoring.

Performance Targets:
- Sub-second metric collection (<500ms)
- Multi-dimensional performance tracking
- Anomaly detection with 95% accuracy
- Trend analysis and forecasting
- SLA monitoring and reporting
- Performance dashboard integration

Author: Manufacturing Line Control System
Created: Week 14 - Performance Optimization Phase
"""

import time
import threading
import asyncio
import json
import statistics
from abc import ABC, abstractmethod
from collections import defaultdict, deque
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Union, Callable, Tuple
from concurrent.futures import ThreadPoolExecutor, Future
import logging
import queue
import uuid
import math
import traceback
import psutil
import os


class MetricType(Enum):
    """Types of performance metrics."""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"
    TIMER = "timer"


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"
    FATAL = "fatal"


class MetricAggregation(Enum):
    """Metric aggregation methods."""
    SUM = "sum"
    AVERAGE = "average"
    MINIMUM = "minimum"
    MAXIMUM = "maximum"
    COUNT = "count"
    PERCENTILE_95 = "p95"
    PERCENTILE_99 = "p99"


@dataclass
class MetricValue:
    """Individual metric value with timestamp."""
    timestamp: datetime
    value: float
    labels: Dict[str, str] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            'timestamp': self.timestamp.isoformat(),
            'value': self.value,
            'labels': self.labels
        }


@dataclass
class Metric:
    """Performance metric definition."""
    name: str
    type: MetricType
    description: str
    unit: str = ""
    labels: Dict[str, str] = field(default_factory=dict)
    values: deque = field(default_factory=lambda: deque(maxlen=1000))
    
    def add_value(self, value: float, labels: Optional[Dict[str, str]] = None, 
                  timestamp: Optional[datetime] = None) -> None:
        """Add a metric value."""
        if timestamp is None:
            timestamp = datetime.now()
        
        combined_labels = self.labels.copy()
        if labels:
            combined_labels.update(labels)
        
        metric_value = MetricValue(timestamp, value, combined_labels)
        self.values.append(metric_value)
    
    def get_latest_value(self) -> Optional[MetricValue]:
        """Get the most recent metric value."""
        return self.values[-1] if self.values else None
    
    def get_values_in_range(self, start_time: datetime, end_time: datetime) -> List[MetricValue]:
        """Get metric values within time range."""
        return [
            mv for mv in self.values
            if start_time <= mv.timestamp <= end_time
        ]
    
    def aggregate(self, aggregation: MetricAggregation, 
                  start_time: Optional[datetime] = None,
                  end_time: Optional[datetime] = None) -> Optional[float]:
        """Aggregate metric values."""
        if start_time and end_time:
            values = [mv.value for mv in self.get_values_in_range(start_time, end_time)]
        else:
            values = [mv.value for mv in self.values]
        
        if not values:
            return None
        
        if aggregation == MetricAggregation.SUM:
            return sum(values)
        elif aggregation == MetricAggregation.AVERAGE:
            return statistics.mean(values)
        elif aggregation == MetricAggregation.MINIMUM:
            return min(values)
        elif aggregation == MetricAggregation.MAXIMUM:
            return max(values)
        elif aggregation == MetricAggregation.COUNT:
            return len(values)
        elif aggregation == MetricAggregation.PERCENTILE_95:
            return statistics.quantiles(values, n=20)[18] if len(values) >= 20 else max(values)
        elif aggregation == MetricAggregation.PERCENTILE_99:
            return statistics.quantiles(values, n=100)[98] if len(values) >= 100 else max(values)
        
        return None


@dataclass
class ThresholdRule:
    """Threshold-based alerting rule."""
    metric_name: str
    operator: str  # gt, gte, lt, lte, eq, neq
    threshold: float
    duration_seconds: int = 60  # How long condition must persist
    severity: AlertSeverity = AlertSeverity.WARNING
    description: str = ""
    labels: Dict[str, str] = field(default_factory=dict)
    
    def evaluate(self, metric: Metric) -> bool:
        """Evaluate if threshold rule is triggered."""
        latest_value = metric.get_latest_value()
        if not latest_value:
            return False
        
        value = latest_value.value
        
        if self.operator == "gt":
            return value > self.threshold
        elif self.operator == "gte":
            return value >= self.threshold
        elif self.operator == "lt":
            return value < self.threshold
        elif self.operator == "lte":
            return value <= self.threshold
        elif self.operator == "eq":
            return value == self.threshold
        elif self.operator == "neq":
            return value != self.threshold
        
        return False


@dataclass
class PerformanceAlert:
    """Performance monitoring alert."""
    id: str
    metric_name: str
    rule: ThresholdRule
    triggered_at: datetime
    resolved_at: Optional[datetime] = None
    current_value: Optional[float] = None
    description: str = ""
    severity: AlertSeverity = AlertSeverity.WARNING
    labels: Dict[str, str] = field(default_factory=dict)
    
    @property
    def is_active(self) -> bool:
        """Check if alert is still active."""
        return self.resolved_at is None
    
    @property
    def duration_seconds(self) -> int:
        """Get alert duration in seconds."""
        end_time = self.resolved_at or datetime.now()
        return int((end_time - self.triggered_at).total_seconds())


@dataclass
class SLADefinition:
    """Service Level Agreement definition."""
    name: str
    metric_name: str
    target_value: float
    operator: str  # gt, gte, lt, lte
    measurement_window_minutes: int = 60
    evaluation_frequency_minutes: int = 5
    description: str = ""
    
    def evaluate_sla(self, metric: Metric) -> Tuple[bool, float]:
        """
        Evaluate SLA compliance.
        
        Returns:
            Tuple of (is_compliant, actual_value)
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=self.measurement_window_minutes)
        
        # Get average value in window
        values = [mv.value for mv in metric.get_values_in_range(start_time, end_time)]
        if not values:
            return False, 0.0
        
        actual_value = statistics.mean(values)
        
        if self.operator == "gt":
            is_compliant = actual_value > self.target_value
        elif self.operator == "gte":
            is_compliant = actual_value >= self.target_value
        elif self.operator == "lt":
            is_compliant = actual_value < self.target_value
        elif self.operator == "lte":
            is_compliant = actual_value <= self.target_value
        else:
            is_compliant = False
        
        return is_compliant, actual_value


@dataclass
class SystemResourceMetrics:
    """System resource utilization metrics."""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_available_gb: float
    disk_usage_percent: float
    disk_read_mb_s: float
    disk_write_mb_s: float
    network_sent_mb_s: float
    network_recv_mb_s: float
    process_count: int
    thread_count: int
    open_files: int
    load_average_1m: float = 0.0
    load_average_5m: float = 0.0
    load_average_15m: float = 0.0


class AnomalyDetector:
    """Statistical anomaly detection for metrics."""
    
    def __init__(self, window_size: int = 100, sensitivity: float = 2.0):
        self.window_size = window_size
        self.sensitivity = sensitivity  # Standard deviations from mean
        self.baseline_values: Dict[str, deque] = defaultdict(lambda: deque(maxlen=window_size))
    
    def is_anomaly(self, metric_name: str, value: float) -> Tuple[bool, float]:
        """
        Detect if value is anomalous.
        
        Returns:
            Tuple of (is_anomaly, anomaly_score)
        """
        baseline = self.baseline_values[metric_name]
        
        # Need sufficient history for detection
        if len(baseline) < 10:
            baseline.append(value)
            return False, 0.0
        
        # Calculate statistical measures
        mean_val = statistics.mean(baseline)
        std_val = statistics.stdev(baseline) if len(baseline) > 1 else 0.0
        
        if std_val == 0:
            anomaly_score = 0.0
        else:
            anomaly_score = abs(value - mean_val) / std_val
        
        is_anomaly = anomaly_score > self.sensitivity
        
        # Update baseline with current value
        baseline.append(value)
        
        return is_anomaly, anomaly_score


class MetricCollector(ABC):
    """Abstract base class for metric collectors."""
    
    @abstractmethod
    def collect_metrics(self) -> Dict[str, Any]:
        """Collect metrics and return as dictionary."""
        pass
    
    @abstractmethod
    def get_collector_name(self) -> str:
        """Get collector name."""
        pass


class SystemResourceCollector(MetricCollector):
    """System resource metrics collector."""
    
    def __init__(self):
        self.last_disk_io = None
        self.last_network_io = None
        self.last_collection_time = None
    
    def collect_metrics(self) -> Dict[str, Any]:
        """Collect system resource metrics."""
        current_time = time.time()
        
        try:
            # CPU metrics
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            # Memory metrics
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_available_gb = memory.available / (1024 ** 3)
            
            # Disk metrics
            disk_usage = psutil.disk_usage('/')
            disk_usage_percent = disk_usage.percent
            
            # Disk I/O rates
            disk_io = psutil.disk_io_counters()
            disk_read_mb_s = 0.0
            disk_write_mb_s = 0.0
            
            if self.last_disk_io and self.last_collection_time:
                time_delta = current_time - self.last_collection_time
                if time_delta > 0:
                    read_delta = disk_io.read_bytes - self.last_disk_io.read_bytes
                    write_delta = disk_io.write_bytes - self.last_disk_io.write_bytes
                    disk_read_mb_s = (read_delta / time_delta) / (1024 * 1024)
                    disk_write_mb_s = (write_delta / time_delta) / (1024 * 1024)
            
            self.last_disk_io = disk_io
            
            # Network I/O rates
            network_io = psutil.net_io_counters()
            network_sent_mb_s = 0.0
            network_recv_mb_s = 0.0
            
            if self.last_network_io and self.last_collection_time:
                time_delta = current_time - self.last_collection_time
                if time_delta > 0:
                    sent_delta = network_io.bytes_sent - self.last_network_io.bytes_sent
                    recv_delta = network_io.bytes_recv - self.last_network_io.bytes_recv
                    network_sent_mb_s = (sent_delta / time_delta) / (1024 * 1024)
                    network_recv_mb_s = (recv_delta / time_delta) / (1024 * 1024)
            
            self.last_network_io = network_io
            
            # Process metrics
            process_count = len(psutil.pids())
            
            # Thread count (approximate)
            try:
                thread_count = sum(p.num_threads() for p in psutil.process_iter(['num_threads']) if p.info['num_threads'])
            except:
                thread_count = 0
            
            # Open files count
            try:
                open_files = len(psutil.Process().open_files())
            except:
                open_files = 0
            
            # Load averages (Unix-like systems)
            load_average_1m = load_average_5m = load_average_15m = 0.0
            try:
                if hasattr(os, 'getloadavg'):
                    load_avg = os.getloadavg()
                    load_average_1m, load_average_5m, load_average_15m = load_avg
            except:
                pass
            
            self.last_collection_time = current_time
            
            return {
                'system_cpu_percent': cpu_percent,
                'system_memory_percent': memory_percent,
                'system_memory_available_gb': memory_available_gb,
                'system_disk_usage_percent': disk_usage_percent,
                'system_disk_read_mb_s': disk_read_mb_s,
                'system_disk_write_mb_s': disk_write_mb_s,
                'system_network_sent_mb_s': network_sent_mb_s,
                'system_network_recv_mb_s': network_recv_mb_s,
                'system_process_count': process_count,
                'system_thread_count': thread_count,
                'system_open_files': open_files,
                'system_load_average_1m': load_average_1m,
                'system_load_average_5m': load_average_5m,
                'system_load_average_15m': load_average_15m,
            }
            
        except Exception as e:
            logging.error(f"SystemResourceCollector error: {e}")
            return {}
    
    def get_collector_name(self) -> str:
        return "SystemResource"


class ApplicationMetricsCollector(MetricCollector):
    """Application-specific metrics collector."""
    
    def __init__(self):
        self.request_count = 0
        self.error_count = 0
        self.response_times: deque = deque(maxlen=100)
        self.last_reset_time = time.time()
    
    def record_request(self, response_time_ms: float, is_error: bool = False) -> None:
        """Record application request metrics."""
        self.request_count += 1
        if is_error:
            self.error_count += 1
        self.response_times.append(response_time_ms)
    
    def collect_metrics(self) -> Dict[str, Any]:
        """Collect application metrics."""
        current_time = time.time()
        time_delta = current_time - self.last_reset_time
        
        # Calculate rates per second
        requests_per_second = self.request_count / time_delta if time_delta > 0 else 0
        errors_per_second = self.error_count / time_delta if time_delta > 0 else 0
        error_rate_percent = (self.error_count / self.request_count * 100) if self.request_count > 0 else 0
        
        # Response time statistics
        avg_response_time = statistics.mean(self.response_times) if self.response_times else 0
        p95_response_time = statistics.quantiles(self.response_times, n=20)[18] if len(self.response_times) >= 20 else avg_response_time
        p99_response_time = statistics.quantiles(self.response_times, n=100)[98] if len(self.response_times) >= 100 else avg_response_time
        
        metrics = {
            'app_requests_per_second': requests_per_second,
            'app_errors_per_second': errors_per_second,
            'app_error_rate_percent': error_rate_percent,
            'app_avg_response_time_ms': avg_response_time,
            'app_p95_response_time_ms': p95_response_time,
            'app_p99_response_time_ms': p99_response_time,
            'app_total_requests': self.request_count,
            'app_total_errors': self.error_count,
        }
        
        return metrics
    
    def get_collector_name(self) -> str:
        return "Application"
    
    def reset_counters(self) -> None:
        """Reset counters for rate calculations."""
        self.request_count = 0
        self.error_count = 0
        self.last_reset_time = time.time()


@dataclass
class PerformanceMonitorConfig:
    """Configuration for performance monitor."""
    collection_interval_seconds: float = 1.0
    metric_retention_hours: int = 24
    anomaly_detection_enabled: bool = True
    anomaly_sensitivity: float = 2.0
    alert_evaluation_interval_seconds: int = 5
    enable_system_metrics: bool = True
    enable_application_metrics: bool = True
    max_metrics_in_memory: int = 100000
    export_metrics_enabled: bool = True
    export_interval_seconds: int = 60


class PerformanceMonitor:
    """
    Real-Time Performance Monitor for Manufacturing System
    
    Provides enterprise-grade performance monitoring with:
    - Sub-second metric collection (<500ms)
    - Multi-dimensional performance tracking
    - Anomaly detection algorithms
    - Trend analysis and forecasting
    - SLA monitoring and reporting
    - Performance dashboard integration
    - Real-time alerting capabilities
    """
    
    def __init__(self, config: Optional[PerformanceMonitorConfig] = None):
        self.config = config or PerformanceMonitorConfig()
        self.logger = logging.getLogger(__name__)
        
        # Metric storage
        self.metrics: Dict[str, Metric] = {}
        self.collectors: List[MetricCollector] = []
        
        # Alerting
        self.threshold_rules: Dict[str, ThresholdRule] = {}
        self.active_alerts: Dict[str, PerformanceAlert] = {}
        self.alert_history: List[PerformanceAlert] = []
        
        # SLA monitoring
        self.sla_definitions: Dict[str, SLADefinition] = {}
        self.sla_compliance_history: Dict[str, List[Tuple[datetime, bool, float]]] = defaultdict(list)
        
        # Anomaly detection
        self.anomaly_detector: Optional[AnomalyDetector] = None
        if self.config.anomaly_detection_enabled:
            self.anomaly_detector = AnomalyDetector(sensitivity=self.config.anomaly_sensitivity)
        
        # Background operations
        self._executor = ThreadPoolExecutor(max_workers=4, thread_name_prefix="PerfMonitor")
        self._shutdown = False
        self._collection_queue = queue.Queue()
        
        # Statistics
        self.collection_stats = {
            'total_collections': 0,
            'failed_collections': 0,
            'last_collection_time': None,
            'average_collection_time_ms': 0.0,
            'collection_times': deque(maxlen=100)
        }
        
        # Initialize default collectors
        if self.config.enable_system_metrics:
            self.add_collector(SystemResourceCollector())
        
        if self.config.enable_application_metrics:
            self.app_collector = ApplicationMetricsCollector()
            self.add_collector(self.app_collector)
        
        # Start monitoring
        self.start_monitoring()
    
    def add_metric(self, name: str, metric_type: MetricType, description: str,
                   unit: str = "", labels: Optional[Dict[str, str]] = None) -> None:
        """Add a new metric definition."""
        if labels is None:
            labels = {}
        
        self.metrics[name] = Metric(
            name=name,
            type=metric_type,
            description=description,
            unit=unit,
            labels=labels
        )
        
        self.logger.info(f"Added metric: {name} ({metric_type.value})")
    
    def record_metric(self, name: str, value: float, labels: Optional[Dict[str, str]] = None,
                      timestamp: Optional[datetime] = None) -> None:
        """Record a metric value."""
        if name not in self.metrics:
            # Auto-create metric if it doesn't exist
            self.add_metric(name, MetricType.GAUGE, f"Auto-created metric: {name}")
        
        self.metrics[name].add_value(value, labels, timestamp)
        
        # Check for anomalies
        if self.anomaly_detector:
            is_anomaly, anomaly_score = self.anomaly_detector.is_anomaly(name, value)
            if is_anomaly:
                self.logger.warning(f"Anomaly detected in {name}: value={value}, score={anomaly_score:.2f}")
                
                # Could trigger an alert here
                self._trigger_anomaly_alert(name, value, anomaly_score)
    
    def add_collector(self, collector: MetricCollector) -> None:
        """Add a metric collector."""
        self.collectors.append(collector)
        self.logger.info(f"Added metric collector: {collector.get_collector_name()}")
    
    def add_threshold_rule(self, rule: ThresholdRule) -> None:
        """Add a threshold-based alerting rule."""
        self.threshold_rules[rule.metric_name] = rule
        self.logger.info(f"Added threshold rule for {rule.metric_name}: {rule.operator} {rule.threshold}")
    
    def add_sla_definition(self, sla: SLADefinition) -> None:
        """Add an SLA definition."""
        self.sla_definitions[sla.name] = sla
        self.logger.info(f"Added SLA definition: {sla.name}")
    
    def get_metric(self, name: str) -> Optional[Metric]:
        """Get metric by name."""
        return self.metrics.get(name)
    
    def get_metric_value(self, name: str, aggregation: Optional[MetricAggregation] = None) -> Optional[float]:
        """Get current or aggregated metric value."""
        metric = self.metrics.get(name)
        if not metric:
            return None
        
        if aggregation:
            return metric.aggregate(aggregation)
        else:
            latest = metric.get_latest_value()
            return latest.value if latest else None
    
    def get_metrics_in_range(self, start_time: datetime, end_time: datetime) -> Dict[str, List[MetricValue]]:
        """Get all metrics within time range."""
        result = {}
        for name, metric in self.metrics.items():
            values = metric.get_values_in_range(start_time, end_time)
            if values:
                result[name] = values
        return result
    
    def start_monitoring(self) -> None:
        """Start performance monitoring."""
        # Start metric collection
        self._executor.submit(self._collection_worker)
        
        # Start alert evaluation
        self._executor.submit(self._alert_evaluation_worker)
        
        # Start SLA evaluation
        self._executor.submit(self._sla_evaluation_worker)
        
        # Start metric export
        if self.config.export_metrics_enabled:
            self._executor.submit(self._export_worker)
        
        self.logger.info("Performance monitoring started")
    
    def stop_monitoring(self) -> None:
        """Stop performance monitoring."""
        self._shutdown = True
        self._executor.shutdown(wait=True)
        self.logger.info("Performance monitoring stopped")
    
    def _collection_worker(self) -> None:
        """Background worker for metric collection."""
        while not self._shutdown:
            try:
                start_time = time.perf_counter()
                
                # Collect metrics from all collectors
                for collector in self.collectors:
                    try:
                        collected_metrics = collector.collect_metrics()
                        timestamp = datetime.now()
                        
                        for metric_name, value in collected_metrics.items():
                            if isinstance(value, (int, float)):
                                self.record_metric(metric_name, float(value), timestamp=timestamp)
                        
                    except Exception as e:
                        self.logger.error(f"Collection failed for {collector.get_collector_name()}: {e}")
                        self.collection_stats['failed_collections'] += 1
                
                # Update collection statistics
                collection_time = (time.perf_counter() - start_time) * 1000
                self.collection_stats['total_collections'] += 1
                self.collection_stats['last_collection_time'] = datetime.now()
                self.collection_stats['collection_times'].append(collection_time)
                
                if self.collection_stats['collection_times']:
                    self.collection_stats['average_collection_time_ms'] = statistics.mean(
                        self.collection_stats['collection_times']
                    )
                
                # Sleep until next collection
                time.sleep(self.config.collection_interval_seconds)
                
            except Exception as e:
                self.logger.error(f"Collection worker error: {e}")
                self.collection_stats['failed_collections'] += 1
                time.sleep(self.config.collection_interval_seconds)
    
    def _alert_evaluation_worker(self) -> None:
        """Background worker for alert evaluation."""
        while not self._shutdown:
            try:
                current_time = datetime.now()
                
                for metric_name, rule in self.threshold_rules.items():
                    metric = self.metrics.get(metric_name)
                    if not metric:
                        continue
                    
                    alert_id = f"{metric_name}_{rule.operator}_{rule.threshold}"
                    
                    if rule.evaluate(metric):
                        # Condition is triggered
                        if alert_id not in self.active_alerts:
                            # New alert
                            alert = PerformanceAlert(
                                id=alert_id,
                                metric_name=metric_name,
                                rule=rule,
                                triggered_at=current_time,
                                current_value=metric.get_latest_value().value if metric.get_latest_value() else None,
                                description=rule.description or f"{metric_name} {rule.operator} {rule.threshold}",
                                severity=rule.severity,
                                labels=rule.labels
                            )
                            self.active_alerts[alert_id] = alert
                            self.alert_history.append(alert)
                            self.logger.warning(f"Alert triggered: {alert.description}")
                    else:
                        # Condition is not triggered
                        if alert_id in self.active_alerts:
                            # Resolve existing alert
                            alert = self.active_alerts[alert_id]
                            alert.resolved_at = current_time
                            del self.active_alerts[alert_id]
                            self.logger.info(f"Alert resolved: {alert.description}")
                
                time.sleep(self.config.alert_evaluation_interval_seconds)
                
            except Exception as e:
                self.logger.error(f"Alert evaluation worker error: {e}")
                time.sleep(self.config.alert_evaluation_interval_seconds)
    
    def _sla_evaluation_worker(self) -> None:
        """Background worker for SLA evaluation."""
        while not self._shutdown:
            try:
                current_time = datetime.now()
                
                for sla_name, sla in self.sla_definitions.items():
                    metric = self.metrics.get(sla.metric_name)
                    if not metric:
                        continue
                    
                    is_compliant, actual_value = sla.evaluate_sla(metric)
                    
                    # Record SLA compliance
                    self.sla_compliance_history[sla_name].append(
                        (current_time, is_compliant, actual_value)
                    )
                    
                    # Keep only recent history
                    cutoff_time = current_time - timedelta(hours=24)
                    self.sla_compliance_history[sla_name] = [
                        entry for entry in self.sla_compliance_history[sla_name]
                        if entry[0] > cutoff_time
                    ]
                    
                    if not is_compliant:
                        self.logger.warning(f"SLA violation: {sla_name} - target: {sla.target_value}, actual: {actual_value:.2f}")
                
                # Sleep until next evaluation
                time.sleep(60)  # Evaluate SLAs every minute
                
            except Exception as e:
                self.logger.error(f"SLA evaluation worker error: {e}")
                time.sleep(60)
    
    def _export_worker(self) -> None:
        """Background worker for metric export."""
        while not self._shutdown:
            try:
                # Export metrics (could be to file, database, or external system)
                self._export_metrics()
                time.sleep(self.config.export_interval_seconds)
                
            except Exception as e:
                self.logger.error(f"Export worker error: {e}")
                time.sleep(self.config.export_interval_seconds)
    
    def _export_metrics(self) -> None:
        """Export metrics to external system."""
        # This is a placeholder - would implement actual export logic
        pass
    
    def _trigger_anomaly_alert(self, metric_name: str, value: float, anomaly_score: float) -> None:
        """Trigger alert for detected anomaly."""
        alert_id = f"anomaly_{metric_name}_{int(time.time())}"
        
        alert = PerformanceAlert(
            id=alert_id,
            metric_name=metric_name,
            rule=None,  # Anomaly-based, not rule-based
            triggered_at=datetime.now(),
            current_value=value,
            description=f"Anomaly detected in {metric_name}: value={value:.2f}, score={anomaly_score:.2f}",
            severity=AlertSeverity.WARNING,
            labels={'anomaly_score': str(anomaly_score)}
        )
        
        # Don't add to active alerts for anomalies (they auto-resolve)
        self.alert_history.append(alert)
        alert.resolved_at = datetime.now()
    
    def get_active_alerts(self) -> List[PerformanceAlert]:
        """Get all active alerts."""
        return list(self.active_alerts.values())
    
    def get_alert_history(self, hours: int = 24) -> List[PerformanceAlert]:
        """Get alert history for specified hours."""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        return [alert for alert in self.alert_history if alert.triggered_at > cutoff_time]
    
    def get_sla_compliance_summary(self) -> Dict[str, Dict[str, Any]]:
        """Get SLA compliance summary."""
        summary = {}
        
        for sla_name, history in self.sla_compliance_history.items():
            if not history:
                continue
            
            total_checks = len(history)
            compliant_checks = sum(1 for _, is_compliant, _ in history if is_compliant)
            compliance_rate = (compliant_checks / total_checks) * 100 if total_checks > 0 else 0
            
            latest_check = history[-1] if history else None
            
            summary[sla_name] = {
                'compliance_rate_percent': compliance_rate,
                'total_checks': total_checks,
                'compliant_checks': compliant_checks,
                'latest_compliant': latest_check[1] if latest_check else None,
                'latest_value': latest_check[2] if latest_check else None,
                'latest_check_time': latest_check[0].isoformat() if latest_check else None
            }
        
        return summary
    
    def get_monitoring_statistics(self) -> Dict[str, Any]:
        """Get performance monitoring statistics."""
        return {
            'collection_stats': self.collection_stats,
            'metric_count': len(self.metrics),
            'active_alert_count': len(self.active_alerts),
            'threshold_rule_count': len(self.threshold_rules),
            'sla_definition_count': len(self.sla_definitions),
            'collector_count': len(self.collectors),
            'total_metric_values': sum(len(metric.values) for metric in self.metrics.values()),
            'anomaly_detection_enabled': self.config.anomaly_detection_enabled,
            'monitoring_uptime_seconds': time.time() - self.collection_stats.get('start_time', time.time())
        }
    
    def record_application_request(self, response_time_ms: float, is_error: bool = False) -> None:
        """Record application request metrics (convenience method)."""
        if hasattr(self, 'app_collector'):
            self.app_collector.record_request(response_time_ms, is_error)
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.stop_monitoring()


# Convenience functions for global performance monitor
_global_performance_monitor: Optional[PerformanceMonitor] = None

def get_performance_monitor(config: Optional[PerformanceMonitorConfig] = None) -> PerformanceMonitor:
    """Get or create global performance monitor instance."""
    global _global_performance_monitor
    if _global_performance_monitor is None:
        _global_performance_monitor = PerformanceMonitor(config)
    return _global_performance_monitor

def record_metric(name: str, value: float, labels: Optional[Dict[str, str]] = None) -> None:
    """Convenience function to record metric."""
    get_performance_monitor().record_metric(name, value, labels)

def record_request(response_time_ms: float, is_error: bool = False) -> None:
    """Convenience function to record application request."""
    get_performance_monitor().record_application_request(response_time_ms, is_error)


if __name__ == "__main__":
    # Demo usage
    logging.basicConfig(level=logging.INFO)
    
    print("Real-Time Performance Monitor Demo")
    print("=" * 50)
    
    # Create performance monitor with configuration
    config = PerformanceMonitorConfig(
        collection_interval_seconds=2.0,
        anomaly_detection_enabled=True,
        anomaly_sensitivity=2.0,
        alert_evaluation_interval_seconds=3
    )
    
    with PerformanceMonitor(config) as monitor:
        # Add custom metrics
        monitor.add_metric("manufacturing_throughput", MetricType.GAUGE, "Production throughput", "units/hour")
        monitor.add_metric("quality_score", MetricType.GAUGE, "Quality score", "percent")
        monitor.add_metric("equipment_temperature", MetricType.GAUGE, "Equipment temperature", "celsius")
        
        # Add threshold rules for alerting
        monitor.add_threshold_rule(ThresholdRule(
            metric_name="manufacturing_throughput",
            operator="lt",
            threshold=90.0,
            severity=AlertSeverity.WARNING,
            description="Manufacturing throughput below target"
        ))
        
        monitor.add_threshold_rule(ThresholdRule(
            metric_name="system_cpu_percent",
            operator="gt",
            threshold=80.0,
            severity=AlertSeverity.CRITICAL,
            description="High CPU usage detected"
        ))
        
        # Add SLA definition
        monitor.add_sla_definition(SLADefinition(
            name="response_time_sla",
            metric_name="app_avg_response_time_ms",
            target_value=200.0,
            operator="lt",
            measurement_window_minutes=5,
            description="Response time should be under 200ms"
        ))
        
        print("\n1. Monitoring Setup Complete")
        print(f"Metrics: {len(monitor.metrics)}")
        print(f"Collectors: {len(monitor.collectors)}")
        print(f"Threshold Rules: {len(monitor.threshold_rules)}")
        print(f"SLA Definitions: {len(monitor.sla_definitions)}")
        
        # Simulate some metric data
        print("\n2. Simulating Manufacturing Data...")
        import random
        
        for i in range(10):
            # Manufacturing metrics
            throughput = 95 + random.uniform(-10, 10)
            quality = 94 + random.uniform(-3, 3)
            temperature = 65 + random.uniform(-5, 15)
            
            monitor.record_metric("manufacturing_throughput", throughput)
            monitor.record_metric("quality_score", quality)
            monitor.record_metric("equipment_temperature", temperature)
            
            # Application requests
            response_time = random.uniform(150, 300)
            is_error = random.random() < 0.05  # 5% error rate
            monitor.record_application_request(response_time, is_error)
            
            print(f"Cycle {i+1}: Throughput={throughput:.1f}, Quality={quality:.1f}%, Temp={temperature:.1f}Â°C")
            time.sleep(1)
        
        # Wait for some monitoring cycles
        print("\n3. Collecting Performance Data...")
        time.sleep(8)
        
        # Show current metrics
        print("\n4. Current Metric Values:")
        for metric_name in ["manufacturing_throughput", "quality_score", "system_cpu_percent", "app_avg_response_time_ms"]:
            value = monitor.get_metric_value(metric_name)
            if value is not None:
                print(f"{metric_name}: {value:.2f}")
        
        # Show active alerts
        print("\n5. Active Alerts:")
        active_alerts = monitor.get_active_alerts()
        if active_alerts:
            for alert in active_alerts:
                print(f"- {alert.severity.value.upper()}: {alert.description}")
        else:
            print("No active alerts")
        
        # Show SLA compliance
        print("\n6. SLA Compliance:")
        sla_summary = monitor.get_sla_compliance_summary()
        for sla_name, summary in sla_summary.items():
            print(f"{sla_name}: {summary['compliance_rate_percent']:.1f}% compliant")
        
        # Show monitoring statistics
        print("\n7. Monitoring Statistics:")
        stats = monitor.get_monitoring_statistics()
        print(f"Total collections: {stats['collection_stats']['total_collections']}")
        print(f"Failed collections: {stats['collection_stats']['failed_collections']}")
        print(f"Average collection time: {stats['collection_stats']['average_collection_time_ms']:.2f}ms")
        print(f"Total metric values: {stats['total_metric_values']}")
        
        print("\nReal-Time Performance Monitor demo completed successfully!")